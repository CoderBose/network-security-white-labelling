{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c0d18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import urllib\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "#Lib require for google drive\n",
    "from googleapiclient.http import MediaFileUpload, MediaIoBaseUpload\n",
    "from io import BytesIO\n",
    "from pydrive2.auth import GoogleAuth\n",
    "from pydrive2.drive import GoogleDrive\n",
    "from pydrive2.files import GoogleDriveFile\n",
    "import mimetypes\n",
    "import magic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c933cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agents = ['Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/37.0.2062.94 Chrome/37.0.2062.94 Safari/537.36',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/600.8.9 (KHTML, like Gecko) Version/8.0.8 Safari/600.8.9',\n",
    " 'Mozilla/5.0 (iPad; CPU OS 8_4_1 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Version/8.0 Mobile/12H321 Safari/600.1.4',\n",
    " 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.10240',\n",
    " 'Mozilla/5.0 (Windows NT 6.3; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0',\n",
    " 'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    " 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    " 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/600.7.12 (KHTML, like Gecko) Version/8.0.7 Safari/600.7.12',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:40.0) Gecko/20100101 Firefox/40.0',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/600.8.9 (KHTML, like Gecko) Version/7.1.8 Safari/537.85.17',\n",
    " 'Mozilla/5.0 (iPad; CPU OS 8_4 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Version/8.0 Mobile/12H143 Safari/600.1.4',\n",
    " 'Mozilla/5.0 (iPad; CPU OS 8_3 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Version/8.0 Mobile/12F69 Safari/600.1.4',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; rv:40.0) Gecko/20100101 Firefox/40.0',\n",
    " 'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    " 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    " 'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; Touch; rv:11.0) like Gecko',\n",
    " 'Mozilla/5.0 (Windows NT 5.1; rv:40.0) Gecko/20100101 Firefox/40.0',\n",
    " 'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3) AppleWebKit/600.6.3 (KHTML, like Gecko) Version/8.0.6 Safari/600.6.3',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3) AppleWebKit/600.5.17 (KHTML, like Gecko) Version/8.0.5 Safari/600.5.17',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    " 'Mozilla/5.0 (iPhone; CPU iPhone OS 8_4_1 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Version/8.0 Mobile/12H321 Safari/600.1.4',\n",
    " 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    " 'Mozilla/5.0 (iPad; CPU OS 7_1_2 like Mac OS X) AppleWebKit/537.51.2 (KHTML, like Gecko) Version/7.0 Mobile/11D257 Safari/9537.53',\n",
    " 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:40.0) Gecko/20100101 Firefox/40.0',\n",
    " 'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    " 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    " 'Mozilla/5.0 (X11; CrOS x86_64 7077.134.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.156 Safari/537.36',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/600.7.12 (KHTML, like Gecko) Version/7.1.7 Safari/537.85.16',\n",
    " 'Mozilla/5.0 (Windows NT 6.0; rv:40.0) Gecko/20100101 Firefox/40.0',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:40.0) Gecko/20100101 Firefox/40.0',\n",
    " 'Mozilla/5.0 (iPad; CPU OS 8_1_3 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Version/8.0 Mobile/12B466 Safari/600.1.4',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/600.3.18 (KHTML, like Gecko) Version/8.0.3 Safari/600.3.18',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.85 Safari/537.36',\n",
    " 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    " 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65a52c",
   "metadata": {},
   "source": [
    "# Google drive to list and create files and folder\n",
    "You need a Oauth2.0 Client to access the GoogleDrive, follow this link https://support.google.com/cloud/answer/6158849?hl=en to create client id. Download the client secret and name the file as client_secrets.json, and stored in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8debf8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleDriveWrapper:\n",
    "    def __init__(self):\n",
    "        auth = GoogleAuth()\n",
    "        # Try to load saved client credentials\n",
    "        auth.LoadCredentialsFile(\"creds.txt\")\n",
    "        if auth.credentials is None:\n",
    "            # Authenticate if they're not there\n",
    "            auth.LocalWebserverAuth()\n",
    "        elif auth.access_token_expired:\n",
    "            # Refresh them if expired\n",
    "            auth.Refresh()\n",
    "        else:\n",
    "            # Initialize the saved creds\n",
    "            auth.Authorize()\n",
    "        # Save the current credentials to a file\n",
    "        auth.SaveCredentialsFile(\"creds.txt\")\n",
    "\n",
    "        self.drive = GoogleDrive(auth)\n",
    "        \n",
    "    def getFileID(self, file_name, parent_id=None, url=False):\n",
    "        \"\"\"\n",
    "            Function to get file id by name, if file is not present, return None\n",
    "        \"\"\"\n",
    "        query = f\"mimeType != 'application/vnd.google-apps.folder' and title='{file_name}'\"\n",
    "        if parent_id:\n",
    "            query+= f\" and '{parent_id}' in parents\"\n",
    "\n",
    "        file_list = self.drive.ListFile({'q':query}).GetList()\n",
    "        for file in file_list:\n",
    "            if url:\n",
    "                return file['alternateLink']\n",
    "            return file['id']\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def getFolderID(self, folder_name, parent_id=None, url=False):\n",
    "        \"\"\"\n",
    "            Function to get folder id by name, if folder is not present, return None\n",
    "        \"\"\"\n",
    "        \n",
    "        #create the query to list the folder\n",
    "        query = f\"mimeType = 'application/vnd.google-apps.folder' and title='{folder_name}'\"\n",
    "        \n",
    "        if parent_id:\n",
    "            query+= f\" and '{parent_id}' in parents\"\n",
    "\n",
    "        file_list = self.drive.ListFile({'q':query}).GetList()\n",
    "        for file in file_list:\n",
    "            if url:\n",
    "                return file['alternateLink']\n",
    "            return file['id']\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def createFolder(self, folder_name, parent_id=None):\n",
    "        \"\"\"\n",
    "            Function to create a folder under a folder (if parent_id is present), return folder_id\n",
    "        \"\"\"\n",
    "        #check if folder exists\n",
    "        folder_id = self.getFolderID(folder_name, parent_id)\n",
    "        \n",
    "        if folder_id:\n",
    "            return folder_id\n",
    "        \n",
    "        # folder not present, create the folder\n",
    "        folder_metadata = {\n",
    "            'title': folder_name,\n",
    "            'mimeType': 'application/vnd.google-apps.folder',\n",
    "        }\n",
    "        \n",
    "        if parent_id:\n",
    "            folder_metadata['parents'] = [{'id': parent_id}]\n",
    "        \n",
    "        folder = self.drive.CreateFile(folder_metadata)\n",
    "        folder.Upload()     \n",
    "        \n",
    "        return folder['id']\n",
    "    \n",
    "    \n",
    "    \n",
    "    def uploadFile(self, file_name, file_path=None, file_url=None, parent_id=None):\n",
    "        \"\"\"\n",
    "            Function to upload File, \n",
    "            \n",
    "            file_name: Name of the file to upload\n",
    "            file_path: Upload the file on file path\n",
    "            file_url: Upload a file from a url\n",
    "            parent_id: Parent Folder Id\n",
    "            \n",
    "            Either Filepath or File_url is required to upload, if both present, picks file_path over file_url\n",
    "        \"\"\"\n",
    "    \n",
    "        # file metadata to upload\n",
    "        file_metadata = {\n",
    "            'title': file_name,\n",
    "            'parents': [{'id': parent_id}] if parent_id else []\n",
    "        }\n",
    "\n",
    "        #upload a file from file_path\n",
    "        if file_path:\n",
    "            #get the mime_type of file\n",
    "            file_metadata['mime_type'] = mimetypes.guess_type(file_path)[0]\n",
    "            \n",
    "            #create the file and set the content of file\n",
    "            media = self.drive.CreateFile(metadata=file_metadata)\n",
    "            media.SetContentFile(filename=file_path)\n",
    "\n",
    "        elif file_url:\n",
    "            \n",
    "            # Make request to load the file from url\n",
    "            headers = {'User-Agent': random.choice(user_agents)}\n",
    "            req = urllib.request.Request(file_url, headers=headers)\n",
    "\n",
    "            #if file size is greater, file loads partially\n",
    "            max_retries = 100\n",
    "            retry_count = 0\n",
    "            remote_file = b\"\"\n",
    "\n",
    "            while retry_count <= max_retries:\n",
    "                try:\n",
    "                    #request to load the file\n",
    "                    response = urllib.request.urlopen(req)\n",
    "                    \n",
    "                    #if request is succefull, read the file response and break the loop\n",
    "                    remote_file = response.read()\n",
    "                    break\n",
    "                except http.client.IncompleteRead as e:\n",
    "                    #if incompleteread exception, load the file partially \n",
    "                    remote_file += e.partial\n",
    "                    retry_count += 1\n",
    "                    print(f\"IncompleteRead error. Retrying... (attempt {retry_count}/{max_retries})\")\n",
    "                    \n",
    "                except urllib.error.HTTPError as err:\n",
    "                    if err.status == 429:\n",
    "                        #exponential backoff time\n",
    "                        delay = min(5*2**retry_count, 40)\n",
    "                        if delay > 40:\n",
    "                            break\n",
    "                            \n",
    "                        \n",
    "                        print(f\"HTTP Error 429: sleeping for {delay} seconds!!\")\n",
    "                        \n",
    "                        time.sleep(delay)\n",
    "                        retry_count += 1\n",
    "                    else:\n",
    "                        print(err)\n",
    "                        break\n",
    "                except Exception as err:\n",
    "                    print(err)\n",
    "                    break\n",
    "\n",
    "            #if no content, return None\n",
    "            if not remote_file:\n",
    "                return None\n",
    "\n",
    "\n",
    "            #get the mime type of a file\n",
    "            file_metadata['mime_type'] = mimetypes.guess_type(file_name)[0]\n",
    "            \n",
    "            #create the file and convet the file to BytesIO since drive requires to read file in string where it encodes the file\n",
    "            media = self.drive.CreateFile(metadata=file_metadata)\n",
    "            media.content = BytesIO(remote_file)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Required either file_path or file_url\")\n",
    "\n",
    "        #uplaod the file\n",
    "        media.Upload()\n",
    "\n",
    "        print(f\"File '{file_name}' has been uploaded to Google Drive.\")\n",
    "\n",
    "        #return the web link\n",
    "        return media['alternateLink']\n",
    "\n",
    "def guessMIMEType(file_path = None, memory_file=None):\n",
    "    try:\n",
    "        #return the mimetype for filepath\n",
    "        if file_path:\n",
    "            return mimetypes.guess_type(file_path)[0]\n",
    "        \n",
    "        #find the mimetype for file stored in memory\n",
    "        elif memory_file:\n",
    "            mime = magic.Magic(mime=True)\n",
    "            mime_type = mime.from_buffer(memory_file.read())\n",
    "\n",
    "            memory_file.seek(0)  # Reset the file pointer after reading the content\n",
    "\n",
    "            return mime_type\n",
    "        else:\n",
    "            raise Exception(\"Required either file_path or memory_file\")\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return 'application/octet-stream'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55ac605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_url_params(url, kwargs):\n",
    "    \"\"\"\n",
    "        Construct new url by adding query params to the url.\n",
    "        \n",
    "        Returns: new url\n",
    "    \"\"\"\n",
    "    \n",
    "    #if no query params add ? else add & at the end of url\n",
    "    url+='?' if not '?' in url else '&'\n",
    "    for i,j in kwargs.items():\n",
    "        url+=f'{i}={j}&'\n",
    "\n",
    "    #strip extra & at the end\n",
    "    return url.rstrip('&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8388266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonScraper:\n",
    "    base_url = \"https://www.amazon.com/s?k=\"\n",
    "\n",
    "    def __init__(self, product_name, chrome_path=r\"C:\\Users\\moink\\Downloads\\chromedriver-win64\\chromedriver.exe\"):\n",
    "        \n",
    "        service = webdriver.chrome.service.Service(executable_path=chrome_path)\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--start-maximized\")\n",
    "        options.add_experimental_option(\"detach\", True)\n",
    "        self.driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "        self.search_url = self.base_url+ re.sub(\"\\s+\", \"+\", product_name)\n",
    "        self.driver.get(self.search_url)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def isNullElement(self, element):\n",
    "        img = element.find_elements(By.XPATH, \".//img[@src]\")\n",
    "        if element.text.strip() or img:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def find_element(self, element, locator, expression, list=True):\n",
    "        result = element.find_elements(locator, expression)\n",
    "        if list:\n",
    "            return result\n",
    "        \n",
    "        return result[0] if result else None\n",
    "\n",
    "    def getProductURLList(self):\n",
    "        WebDriverWait(self.driver, 20).until(EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 's-result-list')]\")))\n",
    "        \n",
    "        qid = self.driver.find_element(By.XPATH, \"//input[@name='qid']\").get_attribute(\"value\")\n",
    "        \n",
    "        \n",
    "        total_page = 1\n",
    "\n",
    "        nav = self.driver.find_element(By.XPATH, \"//div[@role='navigation']\")\n",
    "        next_ele =  nav.find_elements(By.XPATH, \"//a[contains(@class, 's-pagination-item s-pagination-next')]\")\n",
    "        \n",
    "        if next_ele:\n",
    "            total_page = int(next_ele[0].find_element(By.XPATH, \"preceding::*[1]\").text)\n",
    "\n",
    "        product_urls = []\n",
    "        \n",
    "        curr_page = 1\n",
    "        \n",
    "        while True: \n",
    "            for product in self.driver.find_elements(By.XPATH, \"//a[contains(@class, 'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal')]\"):\n",
    "                product_urls.append(product.get_attribute(\"href\"))\n",
    "\n",
    "\n",
    "            curr_page +=1\n",
    "            \n",
    "            if curr_page > total_page:\n",
    "                break\n",
    "\n",
    "            next_page_url = construct_url_params(self.search_url, {'page': curr_page, 'qid': qid, 'ref': f'sr_pg_{curr_page}'})\n",
    "            self.driver.get(next_page_url)\n",
    "        \n",
    "        return product_urls\n",
    "    \n",
    "    def getLeftImage(self):\n",
    "        return [img.get_attribute('src') for img in scraper.driver.find_elements(By.XPATH, \"//div[@id='imageBlock']//div[@class='imgTagWrapper']//img\")]\n",
    "\n",
    "    def getProductNameAndIDFromURL(self):\n",
    "        product_path = urllib.parse.urlparse(self.driver.current_url).path.strip('/').split('/')\n",
    "\n",
    "        product_name = product_path[0].replace(\"-\", \" \")\n",
    "        product_id = product_path[2]\n",
    "        \n",
    "        return product_name, product_id\n",
    "\n",
    "    def parseCenterDiv(self):\n",
    "        #parse centerDiv\n",
    "\n",
    "        product_detail = {}\n",
    "    #     required_div = [\"featurebullets_feature_div\", \"bylineInfo_feature_div\", \"title_feature_div\", \"productOverview_feature_div\"]\n",
    "        \n",
    "        centerDiv = self.driver.find_elements(By.XPATH, \"//div[@id='ppd']\")[0].find_element(By.XPATH, \".//div[@id='centerCol']\")\n",
    "\n",
    "        #get product title\n",
    "        product_detail['product_title'] = centerDiv.find_element(By.ID, 'productTitle').text\n",
    "\n",
    "        #get product brand\n",
    "        product_detail['product_brand'] = re.sub(\"^Visit the|^Brand:|store$\", \"\", centerDiv.find_element(By.ID, 'bylineInfo').text, flags=re.IGNORECASE).strip()\n",
    "        product_detail['product_brand_url'] = centerDiv.find_element(By.ID, 'bylineInfo').get_attribute('href')\n",
    "\n",
    "        #get customer reviews\n",
    "        customer_reviews = centerDiv.find_elements(By.XPATH, \"//div[@id='averageCustomerReviews']\")\n",
    "        if customer_reviews:\n",
    "            product_detail['customer_reviews'] = customer_reviews[0].text.split(\"\\n\")[0]\n",
    "\n",
    "        #get prdouct overview\n",
    "#         product_detail['product_overview'] = {}\n",
    "        \n",
    "        product_overview_feature_div = centerDiv.find_elements(By.XPATH, \"//div[@id='productOverview_feature_div']\")\n",
    "        if product_overview_feature_div:        \n",
    "            soup = BeautifulSoup(product_overview_feature_div[0].get_attribute('innerHTML'), 'html.parser')\n",
    "            for i in soup.findAll('tr'):\n",
    "                td = i.findChildren('td')\n",
    "\n",
    "                #below if elif are just for glance icons\n",
    "                if td[0].find('table'):\n",
    "                    td = td[0].findAll('td')[-1].findAll('span')\n",
    "                elif td[0].find('img'):\n",
    "                    td = td[1].findAll('span')\n",
    "\n",
    "                product_detail[td[0].text.strip()] = td[1].text.strip()\n",
    "                \n",
    "        #parse about section\n",
    "        #replace non ascii characters and continous spaces\n",
    "        product_detail['product_about'] = \"\"\n",
    "        product_about = centerDiv.find_elements(By.XPATH, \".//div[@id='featurebullets_feature_div']//ul\")\n",
    "        \n",
    "        if product_about:\n",
    "            product_detail['product_about'] = re.sub(\"\\s+\", \" \", re.sub(r'[^\\x00-\\x7F]+', \"\", product_about[0].text))\n",
    "\n",
    "\n",
    "        return product_detail\n",
    "\n",
    "    def parseBottomDivs(self):\n",
    "\n",
    "        productDescription = self.driver.find_elements(By.XPATH, \"//div[@id='productDescription']\")\n",
    "        if productDescription:\n",
    "            productDescription = productDescription[0].text.strip()\n",
    "        product_config = {}\n",
    "        misc = {}\n",
    "        long_description = \"\"\n",
    "        brand_story = \"\"\n",
    "        detailBullets = self.driver.find_elements(By.XPATH, \"//div[@id='detailBullets_feature_div' and not(@data-feature-name)]\")\n",
    "\n",
    "        if detailBullets:\n",
    "            for li in detailBullets[0].find_elements(By.TAG_NAME, \"li\"):\n",
    "                spans = li.find_elements(By.XPATH, \".//span/span\")\n",
    "                if spans:\n",
    "                    product_config[spans[0].text.replace(\":\",\"\").strip()] = spans[1].text.strip()\n",
    "        else:\n",
    "            productDetails = self.driver.find_elements(By.XPATH, \"//div[@id='productDetailsNonPets_feature_div']\")\n",
    "            if productDetails:\n",
    "                tables = productDetails[0].find_elements(By.TAG_NAME, \"table\")\n",
    "                for table in tables:\n",
    "                    if scraper.isNullElement(table):\n",
    "                        continue\n",
    "\n",
    "                    if \"productDetails_techSpec\" in table.get_attribute('id'):\n",
    "                        for tr in table.find_elements(By.TAG_NAME, \"tr\"):\n",
    "                            th = tr.find_element(By.TAG_NAME, \"th\")\n",
    "                            td = tr.find_element(By.TAG_NAME, \"td\")\n",
    "                            product_config[th.text.strip()] = td.text.strip()\n",
    "\n",
    "                    else:\n",
    "                        for tr in table.find_elements(By.TAG_NAME, \"tr\"):\n",
    "                            th = tr.find_element(By.TAG_NAME, \"th\")\n",
    "                            td = tr.find_element(By.TAG_NAME, \"td\")\n",
    "                            misc[th.text.strip()] = td.text.strip()\n",
    "\n",
    "\n",
    "        aplus_feature_div = self.driver.find_elements(By.XPATH, \"//div[@id='aplus_feature_div' and div and normalize-space()]\")\n",
    "\n",
    "        images = []\n",
    "        if aplus_feature_div:\n",
    "\n",
    "            long_description = aplus_feature_div[0].find_element(By.XPATH, \".//div[@id='aplus']/div\").text\n",
    "            images = [i.get_attribute(\"src\") for i in aplus_feature_div[0].find_elements(By.TAG_NAME, \"img\")]\n",
    "\n",
    "        aplus_BS_feature_div = self.driver.find_elements(By.XPATH, \"//div[@id='aplusBrandStory_feature_div' and div and normalize-space()]\")\n",
    "\n",
    "        if aplus_BS_feature_div:\n",
    "            brand_story = aplus_BS_feature_div[0].find_element(By.XPATH, \".//div[@id='aplus']/div\").text\n",
    "\n",
    "            images.extend([i.get_attribute(\"src\") for i in aplus_BS_feature_div[0].find_elements(By.TAG_NAME, \"img\")])\n",
    "\n",
    "\n",
    "        btf_contents = self.driver.find_elements(By.XPATH, \"//div[contains(@id, 'btfContent') and div and normalize-space()]\") \n",
    "        btf_description = \"\"\n",
    "        for btf_content in btf_contents:\n",
    "            tables =  btf_content.find_elements(By.TAG_NAME, \"table\")\n",
    "            if tables:\n",
    "                #first table is config and second is misc\n",
    "\n",
    "                for i, table in enumerate(tables):\n",
    "                    for tr in table.find_elements(By.TAG_NAME, \"tr\"):\n",
    "                        td = tr.find_elements(By.TAG_NAME, \"td\")\n",
    "                        product_config[td[0].text.strip()] = td[1].text.strip()\n",
    "\n",
    "            else:\n",
    "                btf_description += btf_content.text.strip()\n",
    "            images.extend([i.get_attribute(\"src\") for i in btf_content.find_elements(By.TAG_NAME, \"img\")])\n",
    "\n",
    "        if not long_description:\n",
    "            long_description = btf_description\n",
    "        elif not brand_story:\n",
    "            brand_story = btf_description\n",
    "        else:\n",
    "            misc['extra_information'] = btf_description\n",
    "\n",
    "        product_details = {\n",
    "            'product_short_description': re.sub(r'[^\\x00-\\x7F]+', '', productDescription) if productDescription else None, \n",
    "            'product_long_description': re.sub(r'[^\\x00-\\x7F]+', '',long_description),\n",
    "            'brand_story': re.sub(r'[^\\x00-\\x7F]+', '', brand_story)\n",
    "\n",
    "        }        \n",
    "\n",
    "        product_details.update(product_config)\n",
    "        return product_details, images\n",
    "\n",
    "    def quit(self):\n",
    "        self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1db72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_contexts(text, target_word, context_size=5):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    # Find all occurrences of the target word\n",
    "    \n",
    "    target_indices = [i for i, token in enumerate(tokens) if token.lower() == target_word.lower()]\n",
    "\n",
    "    # Extract context sentences for each occurrence of the target word\n",
    "    all_contexts = []\n",
    "    for target_index in target_indices:\n",
    "        start_index = max(0, target_index - context_size)\n",
    "        end_index = min(len(tokens), target_index + context_size + 1)\n",
    "        context_words = tokens[start_index:end_index]\n",
    "        context_sentence = ' '.join(context_words)\n",
    "        all_contexts.append(context_sentence)\n",
    "\n",
    "    return all_contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "34f631df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_name(nlp, text):\n",
    "\n",
    "    contexts = get_all_contexts(text, \"app\")\n",
    "\n",
    "    app_name = defaultdict(int)\n",
    "\n",
    "    for context in contexts:\n",
    "        doc = nlp(context)\n",
    "\n",
    "        #iterate through the entities\n",
    "        for ent in doc.ents:\n",
    "            name = re.sub(\"[^a-zA-Z0-9]\", \"\", ent.text.upper())\n",
    "            app_name[name]  +=1\n",
    "\n",
    "\n",
    "    return max(app_name, key=app_name.get) if app_name else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1739fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\moink\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.6.1 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "#download punkt using nltk.download('punkt') and provide the path below\n",
    "nltk.data.path.append(r\".\\tokenizers\")\n",
    "\n",
    "#load the model\n",
    "# nlp = spacy.load(r\"C:\\Users\\moink\\Downloads\\white_label\\model-best\")\n",
    "nlp = spacy.load(r\".\\case_sensitive_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "54535bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = AmazonScraper(\"smart blood pressure monitors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "14c5076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_urls = scraper.getProductURLList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f22e1f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "12858302",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_details= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731350dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for product_url in product_urls[256:]:\n",
    "    print(product_url)\n",
    "    scraper.driver.get(product_url)\n",
    "    product = {}\n",
    "    product_name, product_id = scraper.getProductNameAndIDFromURL()\n",
    "\n",
    "    if product_id not in product_details:\n",
    "        product['id'] = product_id\n",
    "        product['name'] = product_name\n",
    "\n",
    "        main_image = scraper.getLeftImage()[0]\n",
    "        center_div = scraper.parseCenterDiv()\n",
    "\n",
    "        bottom, _ = scraper.parseBottomDivs()\n",
    "\n",
    "        product['long_description'] = bottom['product_long_description'] or bottom['brand_story'] or bottom['product_short_description'] or center_div['product_about']\n",
    "        product['brand'] = center_div['product_brand']\n",
    "\n",
    "\n",
    "        description_list = [center_div['product_about'] , bottom['product_long_description'] , bottom['brand_story'] , bottom['product_short_description']]\n",
    "\n",
    "        product['app_name'] = None\n",
    "        for description in description_list:\n",
    "            \n",
    "            if description:\n",
    "                product['app_name'] = get_app_name(nlp, description.replace(\"\\n\", \" \"))\n",
    "                if product['app_name']:\n",
    "                    break\n",
    "\n",
    "        print(product['app_name'])\n",
    "\n",
    "        product['image_url'] = main_image\n",
    "\n",
    "        product['url'] = product_url\n",
    "        product_details[product_id] = product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "752769d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c07d334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_pd = [product_details[product_detail]['data'] for product_detail in product_details]\n",
    "df = pd.DataFrame(product_details.values())\n",
    "\n",
    "df.to_csv(r\"..\\amazon_smart_blood_pressure_monitors_products_dataset.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_folder_id = \"\"\n",
    "\n",
    "#path to client secrets\n",
    "# You need a Oauth2.0 Client to access the GoogleDrive, follow this link https://support.google.com/cloud/answer/6158849?hl=en \n",
    "#to create client id. Download the client secret and name the file as client_secrets.json, and stored in the same directory as this notebook or set client_config_file attr\n",
    "GoogleAuth.DEFAULT_SETTINGS['client_config_file'] = r\"client_secrets.json\"\n",
    "drive = GoogleDriveWrapper()\n",
    "folder_id = drive.createFolder(\"smart blood pressure monitors\".title(), shared_folder_id)\n",
    "folder_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbce4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in df.iterrows():\n",
    "    image_name = f\"{image['id']}_{image['name'].replace(' ', '-')}.jpg\"\n",
    "    \n",
    "    \n",
    "    #check if file already present\n",
    "    file_id = drive.getFileID(file_name=image_name, parent_id=folder_id)\n",
    "\n",
    "    #file not present\n",
    "    if not file_id:\n",
    "        #upload file under the parent folder with folder id\n",
    "        file_id = drive.uploadFile(file_name=image_name, file_url= image['image_url'], parent_id=folder_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca8bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
